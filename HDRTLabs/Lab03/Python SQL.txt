# import sql types
from pyspark.sql.types import *

# load text file
csv = sc.textFile(
 'wasb:///HdiSamples/HdiSamples/SensorSampleData/building/building.csv'
)


# parse data
data = csv.map(lambda s: s.split(",")).filter(lambda s: s[0] != "BuildingID").map(lambda s:(int(s[0]), int(s[2]), str(s[3]) ))


# create schema
schma = StructType([
  StructField("BuildingID", IntegerType(), False),
  StructField("BuildingAge", IntegerType(), False),
  StructField("HVACProduct", StringType(), False)
])


# create dataframe and register table
df = sqlContext.createDataFrame(data,schma)
df.registerTempTable("tmpBuilding")


# query table
buildings = sqlContext.sql("""SELECT * FROM tmpBuilding
                              WHERE BuildingAge < 20""")
buildings.show()
